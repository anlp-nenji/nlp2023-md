<!DOCTYPE html>
<html lang="ja">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <link rel="stylesheet" type="text/css" href="bootstrap/css/bootstrap.min.css">
  <link rel="stylesheet" type="text/css" href="bootstrap/css/bootstrap-responsive.min.css">
  <link rel="stylesheet" type="text/css" href="normalize.css">
  <link rel="stylesheet" type="text/css" href="nlp20XX.css?202204011100" />

  <!-- [if lt IE 9]> -->
  <!--      <script src="https://html5shim.googlecode.com/svn/trunk/html5.js"></script> -->
  <!--      <![endif -->
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.8.3/jquery.min.js"></script>
  <script src="bootstrap/js/bootstrap.min.js"></script>

  <script type="text/javascript">
    !function ($) {
      $(function () {
        var $window = $(window)
        $('.bs-docs-sidenav').affix({
          offset: {
            top: 0, bottom: 270
          }
        })
      })
    }(window.jQuery)
  </script>

  <title>言語処理学会第28回年次大会表彰一覧（NLP2022）</title>
</head>

<body data-spy="scroll" data-target=".bs-docs-sidebar">
  <div class="container">
    <div class="row">
      <div class="span3 bs-docs-sidebar">
        <div id="menu">
          <ul class="nav nav-list bs-docs-sidenav">
            <li><a href="https://www.anlp.jp/nlp2022/">【メインページ】</a></li>
            <li><a href="#menu">Top</a></li>
            <li><a href="#best">最優秀賞</a></li>
            <li><a href="#outstanding">優秀賞</a></li>
            <li><a href="#encouragement">若手奨励賞</a></li>
            <li><a href="#resource">言語資源賞</a></li>
            <li><a href="#sponsor">スポンサー賞</a></li>
            <li><a href="#committee">委員特別賞</a></li>
          </ul>
        </div> <!-- end of menu -->
      </div> <!-- end of span3 -->

      <div class="span9">
        <div id="logo">
          <h1>言語処理学会第28回年次大会表彰一覧（NLP2022）</h1>
          <a href="index.html"><img src="./logo/NLPlogo_300x100.png" alt="言語処理学会ロゴ" /></a>
        </div><br />

        <h2 id="best">最優秀賞 （全386件中2件）</h2>
        <table>
          <tr><td class="pid"><span id="G1-4">G1-4</span></td><td><span class="title">強化学習における画像キャプションの低識別性問題とLong-Tail分類手法を用いた対処</span></td><tr><td></td><td>本多右京, 渡辺太郎 (NAIST), 松本裕治 (理研)</td><tr><td></td><td class="award_reason">画像キャプション生成において強化学習は有効な手法ですが，一般的な内容のキャプションを生成しやすいという低識別性の問題があります．本論文では，この問題に対処するため，画像分類で用いられているlong-tail分類手法を応用することによって，キャプション中の語彙を増加させる手法を提案しています．実験によって，提案手法が既存モデルと比べて，語彙を増加させるとともに，識別性を顕著に向上させることを確認しています．また，提案手法は学習済みの既存モデルをfine-tuningするものであり，計算コストが低く，実用性も高いと考えられます．これらの貢献から最優秀賞にふさわしいと判断しました．</td></tr>
          <tr><td class="pid"><span id="A3-1">A3-1</span></td><td><span class="title">ニューラル言語モデルの効率的な学習に向けた代表データ集合の獲得</span></td><tr><td></td><td>鈴木潤 (グーグル/東北大), 全炳河, 賀沢秀人 (グーグル)</td><tr><td></td><td class="award_reason">ニューラル言語モデルは近年の自然言語処理タスクの根幹を担う基盤技術ですが，モデル構築には潤沢な計算リソースが必要になります．本論文では，ニューラル言語モデルを構築する際に，学習データを全て用いるのではなく，選択した代表的なデータ集合のみを用いて学習した場合に，性能を維持できるか否かを検証しています．実験によって，提案手法を用いることで，21分の1程度までに学習データを削減したとしても，全ての学習データを用いて学習した場合と比較して性能が維持できるということが示されました．本手法を用いることで，ニューラル言語モデルの構築を様々な研究者ができるようになると考えられ，有用性，発展性の高い研究であると言えます．これらの貢献から最優秀賞にふさわしいと判断しました．</td></tr>
        </table>

        <h2 id="outstanding">優秀賞（全386件中7件）</h2>
        <table>
          <tr><td class="pid"><span id="D1-4">D1-4</span></td><td><span class="title">状況別感情極性日本語辞書の作成とその活用</span></td><tr><td></td><td>高田篤志 (東大), 狩野芳伸 (静大), 山﨑俊彦 (東大)</td><tr><td></td><td class="award_reason">既存の感情極性辞書は単語に対してポジティブかネガティブとラベル付けされているものか，いくつかのクラスカテゴリに単語を分類しているものが多いです．ところが，単語は文脈や状況によって様々な意味を持ち，異なる印象を与えることがあります．そこで，本論文では20種類の状況を設定し，各状況に対してクラウドソーシングを利用して感情極性ラベルを付与した日本語辞書SiSPを作成しています．そして，その辞書を用いることで極性予測の性能が向上することを実験で示しています．文脈を考慮した解析は言語処理において重要であり，また本辞書はオープンソースで公開予定としておりコミュニティへの貢献も大きいため，優秀賞にふさわしいと判断しました．</td></tr>
          <tr><td class="pid"><span id="A2-5">A2-5</span></td><td><span class="title">Transformerを多層にする際の勾配消失問題と解決法について</span></td><tr><td></td><td>高瀬翔 (東工大), 清野舜 (理研/東北大), 小林颯介 (PFN/東北大), 鈴木潤 (東北大/理研)</td><tr><td></td><td class="award_reason">本論文は，Transformerの多層化において，Post Layer Normalizationの学習の安定性向上に取り組んでいます．勾配に関する解析を通して，Transformerのオリジナルの構造での多層化における学習の不安定性はLayer Normalizationによる勾配消失であることを示し，層内のLayer Normalizationを回避するためのResidual Connectionを追加したB2T Connectionを提案しています．機械翻訳での実験により，提案手法の有効性を示しています．実験的な合理化を入念に行い，最終的な実験でもその有用性を示しているという点でインパクトと完成度の高い研究です．今後のTransformerに大きな影響を与える可能性があると考えられることから，優秀賞にふさわしい論文と判断しました．</td></tr>
          <tr><td class="pid"><span id="G2-3">G2-3</span></td><td><span class="title">IMPARA: パラレルデータにおける修正の影響度に基づいた文法誤り訂正の自動評価法</span></td><tr><td></td><td>前田航希, 金子正弘, 岡崎直観 (東工大)</td><tr><td></td><td class="award_reason">本論文は，誤文と正文の組からなるパラレルデータのみを用い，修正の影響度を考慮しながら文法誤り訂正の評価尺度を学習する手法であるIMPARAを提案しています．具体的には，誤文と正文の組から，編集に対する影響度を算出し，訂正文の良し悪しに関する順序関係を学習するためのデータを作成します．そして，このデータから，自動的にラベル付けをする評価尺度を学習します．本手法は，実験により，人手評価との相関において既存手法と同等以上の性能を示すこと，評価対象となるコーパスが持つ訂正の特性を考慮した自動評価を行えることが示されています．文法誤り訂正タスクのデータセット作成コストの削減に大きく貢献する成果であり，自動採点等への適用など大きな可能性が期待されることから，優秀賞にふさわしい論文と判断しました．</td></tr>
          <tr><td class="pid"><span id="E3-3">E3-3</span></td><td><span class="title">論述リビジョンのためのメタ評価基盤</span></td><tr><td></td><td>三田雅人 (理研), 坂口慶祐 (Allen Institute for Artificial Intelligence), 萩原正人 (Earth Species Project/Octanove Labs), 水本智也 (フューチャー/理研), 鈴木潤, 乾健太郎 (東北大/理研)</td><tr><td></td><td class="award_reason">本論文は，文書単位で論述の流れや一貫性・結束性に関する編集を行う論述リビジョンタスクを対象に，自動評価尺度の開発促進のためのメタ評価基盤を提案しています．メタ評価基盤は，論文に対して専門家がリビジョンをアノテーションしたデータセットと，編集事例毎の二値分類に基づくメタ評価手法によって実現しています．また，提案した基盤により，大規模言語モデルを用いて作成した評価尺度のメタ評価を行い，基盤の有用性を示しています．本研究は，自動評価尺度の開発，ひいては，論述リビジョンという挑戦的な課題に取り組む研究を促進するものです．これらの貢献と将来性に鑑みて，優秀賞にふさわしいと判断しました．</td></tr>
          <tr><td class="pid"><span id="PT2-7">PT2-7</span></td><td><span class="title">知識グラフ埋め込みにおける負例サンプリング損失の分析</span></td><tr><td></td><td>上垣外英剛 (東工大), 林克彦 (群馬大)</td><tr><td></td><td class="award_reason">本論文は，知識グラフ埋め込みの学習時にしばしば用いられる負例サンプリング損失に関して，その中で用いられるマージン項，負例サンプル数，サブサンプリング法の選択の意味付けを数式に基づく解釈にて提示しています．従来，これらの人手により選択するハイパーパラメータは，経験的な知見に基づいて選択されることがほとんどでした．そのため，実際に利用している設定が，具体的にどういった効果をもたらしているのかを深く理解することができていませんでした．それに対して，数式的な解析により導出される等価性などを根拠に具体的な意味付けを与えることで，利用者に一定の理解を提供することに成功しています．最近の自然言語処理分野において経験的な研究が多い中で理論的な解析に基づいて方法論を理解／分析しようという研究の考え方なども含めて，多くの後続研究の参考になることが期待されます．これらのことから優秀賞にふさわしい論文といえます．</td></tr>
          <tr><td class="pid"><span id="E5-4">E5-4</span></td><td><span class="title">機械・人の双方が言語で概念を説明可能なFew-shot画像分類</span></td><tr><td></td><td>西田光甫, 西田京介, 西岡秀一 (NTT)</td><tr><td></td><td class="award_reason">本論文では，few-shot画像分類問題を題材に，機械学習モデルが新規の概念を自然言語の説明から獲得し，モデルの挙動を自然言語によって説明することに取り組んでいます．提案手法のLIDEは，テキストデコーダによる説明の生成と，テキストエンコーダによる説明の入力によってfew-shot画像分類の性能を改善することに成功しています．また，人間による説明をテキストエンコーダに入力することで性能がさらに向上することや，生成された説明の品質が画像分類の正否と相関を持つことも確認しており，多くの後続研究にとって重要な知見となることが期待されます．これらの貢献から優秀賞にふさわしいと判断しました．</td></tr>
          <tr><td class="pid"><span id="D7-4">D7-4</span></td><td><span class="title">創発言語でもHarrisの分節原理は成り立つのか？</span></td><tr><td></td><td>上田亮, 石井太河, 宮尾祐介 (東大)</td><tr><td></td><td class="award_reason">本論文は，シミュレーションにおいてエージェント間で生じる人工的な言語である創発言語について，Harrisの分節原理が成り立つかを検証したものです．創発言語は近年注目を集めつつある研究対象で，創発言語においても自然言語の性質が観察されるかを検証する研究が行われるようになっていますが，Harrisの分節原理に着目したものはなく，新規性が認められます．分析の結果，創発言語はHarrisの分節原理が成立するためのいくつかの前提条件を満たすものの，統計的な情報から得られる分節境界が必ずしも意味的に妥当なものであるとは限らない可能性が示唆されました．自然言語の性質の多くが語や節などの単位を仮定して語られることを踏まえると，創発言語の上でも分節を定義しようとする試みは重要な一歩であり，優秀賞にふさわしいと判断しました．</td></tr>
        </table>

        <h2 id="encouragement">若手奨励賞（対象280件中12件）</h2>
        <table>
          <tr><td class="pid"><span id="C1-3">C1-3</span></td><td><span class="title">テキストと視覚的に表現された情報の融合理解に基づくインフォグラフィック質問応答</span></td><tr><td></td><td>田中涼太 (NTT)</td><tr><td></td><td class="award_reason">本論文は，言語と視覚の融合的な理解に向けて，情報を視覚的に表現した画像（インフォグラフィック）に対する質問応答モデルを提案しています．提案モデルの特長は，テキストと視覚物体の配置関係の学習，および算術演算理解のためのデータ拡張の2点です．これらの両方が質問応答の精度向上に貢献することを実験によって示すとともに，ICDAR 2021 CompetitionのInfographicVQAタスクにおいて優秀な成績を収めています．実用面での利活用も期待できることにも鑑みて，若手奨励賞にふさわしいと判断しました．</td></tr>
          <tr><td class="pid"><span id="F2-5">F2-5</span></td><td><span class="title">Pre-trained Transformerによる引用文脈を考慮した引用ネットワーク埋め込み</span></td><tr><td></td><td>大萩雅也 (東大)</td><tr><td></td><td class="award_reason">本論文では，Pre-trained Transformerを用いて引用文脈を考慮したネットワーク埋め込みを作成する新たな手法を提案しています．ネットワーク埋め込みを作成するにあたり，Masked Paper Predictionという新しいタスクを提案し，加えて，Structure-Aware Cross-Entropy Lossという新しい損失関数も提案しています．評価実験の結果，既存手法に対して優位な結果を示しています．引用ネットワーク埋め込みという新しい取り組みを行っており，今後の発展も期待できることから，若手奨励賞に値すると判断しました．</td></tr>
          <tr><td class="pid"><span id="E3-5">E3-5</span></td><td><span class="title">大学入学共通テスト試行調査における短答式記述答案の完全自動採点</span></td><tr><td></td><td>岡知樹 (東大)</td><tr><td></td><td class="award_reason">本論文は，大学入学共通テスト試行調査の国語の短答式記述問題を対象に，手書きで書かれた答案を完全に自動で採点するシステムの開発と評価について報告しています．畳み込みニューラルネットワークのアンサンブル学習による手書き文字認識モデルとBERTのファインチューニングによる自動採点モデルを組み合わせることで実現した提案システムを，約6万件の答案データを用いて評価・検証しています．大規模な現実のデータを用いて，現在の採点技術の可能性を具体的に示した本研究は，今後の研究開発の参照点となる有用なものであることから，若手奨励賞にふさわしいと判断しました．</td></tr>
          <tr><td class="pid"><span id="G3-4">G3-4</span></td><td><span class="title">多言語文符号化器の言語表現と意味表現の分離に基づく機械翻訳の品質推定</span></td><tr><td></td><td>黒田勇斗 (愛媛大)</td><tr><td></td><td class="award_reason">本論文は，文表現から抽出した言語非依存の意味表現を用いて，機械翻訳の品質推定を行う手法を提案しています．教師なし品質推定では，多言語文符号化器により得られる文表現が言語の影響を強く受け，言語間の意味的類似度の推定が不正確になるという課題があります．これに対して，提案手法は，意味表現に言語固有の情報が含まれないように，敵対的学習を用いる点が特徴的です．WMT20の品質推定タスクにおける評価実験の結果，提案手法はベースラインの多言語文符号化器LaBSEを一貫して改善すること，また，特に少資源言語対においては他の複数のアプローチと比較しても高い性能を達成することが示されています．言語表現と意味表現を分離するというアイディアの有用性が示されており，今後の発展が期待できることから，若手奨励賞に値すると判断しました．</td></tr>
          <tr><td class="pid"><span id="PH2-7">PH2-7</span></td><td><span class="title">シフト付き絶対位置埋め込み</span></td><tr><td></td><td>清野舜 (理研/東北大)</td><tr><td></td><td class="award_reason">本論文は，Transformer における位置表現の改良に取り組み，入力系列の各位置インデックスを，乱数から生成したオフセットでシフトさせる，シフト付き絶対位置埋め込み（SHAPE）を提案しています．実験の結果，本手法が相対位置埋め込みと同等の性能を発揮しつつ，絶対位置埋め込みと同等の速度で動作することを示しています．位置埋め込みの後段の注意機構の改変を強制しない優れた手法であり，絶対位置とシフト不変性という両立しそうにない方向性に対してシンプルな方法でアプローチしている点は高く評価できます．評価・分析も十分なされており，論文としての完成度も高く，今後の位置埋め込みに影響を与える研究と考えられることから，若手奨励賞にふさわしいと判断しました．</td></tr>
          <tr><td class="pid"><span id="PH2-8">PH2-8</span></td><td><span class="title">線型部分空間に基づく学習済み単語埋込空間上の集合演算</span></td><tr><td></td><td>石橋陽一 (NAIST)</td><tr><td></td><td class="award_reason">本論文では，事前学習済み単語埋め込み空間において集合と集合演算を定義することに取り組んでいます．具体的には，線型部分空間に基づく集合演算である量子論理に着目し，埋め込み空間でも同様に線型部分空間が言語的な集合演算として機能することを示しています．実験では文の意味的類似性タスクにて提案法の有効性を検証しています．必ずしも単純なベースラインよりも顕著に高い効果が得られているわけではないですが，理論的裏付けを持つ方法論が十分な性能を示すことを実証しています．今後のさらなる発展も期待できる研究であることから，若手奨励賞に値する論文と判断しました．</td></tr>
          <tr><td class="pid"><span id="A5-1">A5-1</span></td><td><span class="title">単語ベクトルの長さは意味の強さを表す</span></td><tr><td></td><td>大山百々勢 (京大/理研)</td><tr><td></td><td class="award_reason">本論文では，単語ベクトルの長さが意味の強さをエンコードすることについて分析しています．意味の強さとして，各単語の周辺単語分布とコーパス全体の単語分布のKullback-Leibler（KL）情報量を提案し，その補正値が品詞の違いを識別できることを実験により示しています．さらに，Skip-gram with Negative Samplingによって得られる単語ベクトルの長さがKL情報量，つまり意味の強さに相当することを理論的かつ実験的に示しています．分析結果は興味深く，また単語ベクトルは深層学習に基づく手法の基盤であり，今後の発展が期待できる研究であることから，若手奨励賞に値すると判断しました．</td></tr>
          <tr><td class="pid"><span id="G5-2">G5-2</span></td><td><span class="title">Holographic EmbeddingsによるCCG構文解析</span></td><tr><td></td><td>山木良輔 (立命館大)</td><tr><td></td><td class="award_reason">本論文では，CCG構文解析の課題に対して，単語分散表現から句や文の分散表現を再帰的に構成し，文の構成要素間の依存関係を明示的にモデリングする手法を提案しています．具体的には，知識グラフをベクトル空間に埋め込むために提案されたHolographic Embeddingsを用いて，階層的な句の分散表現を得ています．実験では，特定の条件下では従来研究と比較して最も良い評価結果を示すなど，良好な性能を示しています．非常に独自性の高い研究に位置付けられ，また，実験結果も有望であり今後の発展も十分に期待できることから，若手奨励賞に値する論文と判断しました．</td></tr>
          <tr><td class="pid"><span id="PH3-13">PH3-13</span></td><td><span class="title">主観と客観の感情極性分類のための日本語データセット</span></td><tr><td></td><td>宮内裕人 (愛媛大)</td><tr><td></td><td class="award_reason">感情分析の先行研究は，感情極性（Sentiment）・基本感情（Emotion）・書き手の感情（主観感情）・読み手の感情（客観感情）といった様々な観点で行われてきています．本論文ではそれらを包括的に扱った先行研究は存在しないと指摘し，主観と客観の両方の立場から感情極性のラベルを付与した日本語データセットを作成しました．そして実験において，単一の感情のみが含まれるテキストよりも複数の感情が共起するテキストが，読み手にとって書き手の感情を読み取りやすいことを示しました．本データセットは一般公開されており，今後の感情分析に関する研究に大きく貢献すると考えられるため，若手奨励賞にふさわしいと判断しました．</td></tr>
          <tr><td class="pid"><span id="PT4-3">PT4-3</span></td><td><span class="title">日本語文法誤り訂正の流暢性評価に向けたデータ作成</span></td><tr><td></td><td>木山朔 (都立大)</td><tr><td></td><td class="award_reason">既存の日本語文法誤り訂正の評価データでは，文法に関する最小限の編集に基づき訂正文を作成しており，文法的ではあるものの流暢性に欠けることから，こうした評価データに依存してモデルを開発すると文法的かつ流暢な出力をするモデルが正当に評価されないという問題があります．本論文では，こうした状況を受け，Lang-8コーパスに含まれる学習者が書いた作文に対し，日本語母語話者5人が文法的に正しくかつ流暢性に配慮した訂正を行うことにより，日本語文法誤り訂正のための流暢性評価データを作成しました．これはモデルの流暢性も含めた評価を可能にする有効なデータであることから，若手奨励賞に値すると判断しました．</td></tr>
          <tr><td class="pid"><span id="PT4-5">PT4-5</span></td><td><span class="title">Teacher-Student学習を利用したラベル誤りを含むデータにおける固有表現認識の性能向上</span></td><tr><td></td><td>田川裕輝 (富士フイルム)</td><tr><td></td><td class="award_reason">本論文では，Teacher-Student学習を利用したラベルノイズを含む学習データでの固有表現認識の学習方法を提案しています．学習データに含まれるノイズが含まれることを前提に実験が行われており，加えて，ノイズ割合を変化させて評価を行うことで，提案手法の頑健性を示しています．また，他の手法とも比較しており，信頼性の高い結果となっています．信頼性・実用性の高さから，若手奨励賞にふさわしいと判断しました．</td></tr>
          <tr><td class="pid"><span id="F8-3">F8-3</span></td><td><span class="title">マイクロブログからの消失エンティティの検知</span></td><tr><td></td><td>赤崎智 (東大)</td><tr><td></td><td class="award_reason">本論文では，死没・閉店といったエンティティの存在が実世界から無くなる「消失」という概念を定義しています．この「消失」の認識はトレンドの分析等において必要である一方，エンティティは消失しても言及され続けたり，長期間言及されていなくてもそれが消失ではなかったりするため，エンティティ辞書を用意して出現頻度を監視するという単純な方法ではうまくいかないとしています．そこで，本論文では，Twitterの大規模アーカイブから，消失エンティティを収集し，日英データセットを構築した上で，消失エンティティの自動検知手法の提案及び評価を行っています．新規性・独自性の高いタスクとデータセットを設計し，一定の性能を示すモデルも提案していることから，若手奨励賞にふさわしいと判断しました．</td></tr>
        </table>

        <h2 id="resource">言語資源賞（対象92件中2件）</h2>
        <table>
          <tr><td class="pid"><span id="E8-1">E8-1</span></td><td><span class="title">『日本語日常会話コーパス』の設計と特徴</span></td><tr><td></td><td>小磯花絵, 天谷晴香, 石本祐一, 居關友里子, 臼田泰如, 柏野和佳子, 川端良子, 田中弥生 (国語研), 伝康晴 (千葉大), 西川賢哉, 渡邊友香 (国語研)</td><tr><td></td><td class="award_reason">本論文は「日本語日常会話コーパス」を構築しています．このコーパスは，日常における様々な場面について，年齢・性別をバランスさせた40名の話者による会話を収録しています．コーパスの規模も大きく，会話時間は200時間，会話数は577，のべ話者数は1675名となっています．会話の音声データ，転記テキストに加え，会話の様子を撮影した映像データを含む点に特徴があります．転記テキストには，人手修正された短単位の形態素情報と自動付与された長単位の形態素情報がタグ付けされています．また，全体のうち20時間分の会話を抜粋したコアデータについては，人手修正された長単位の形態素，文節間の係り受け関係，談話行為，韻律の情報が付与されています．同コーパスは2022年3月に一般公開されます．日本語の日常会話を収録した豊富なアノテーションを含む大規模なコーパスであり，対話の研究に幅広く利用できる価値の高い言語資源であると言えます．</td></tr>
          <tr><td class="pid"><span id="E8-4">E8-4</span></td><td><span class="title">JGLUE: 日本語言語理解ベンチマーク</span></td><tr><td></td><td>栗原健太郎, 河原大輔 (早大), 柴田知秀 (ヤフー)</td><tr><td></td><td class="award_reason">本論文は，英語のGLUEにならい，複数のデータセットからなる日本語の言語理解処理のベンチマーク JGLUEを構築しています．文書分類タスクについては，日本語の商品レビューにpositive,negativeの二値のラベルを付与した「MARC-ja」と，日本語容認性判断データセット「JCoLA」を含みます．文ペア分類タスクについては，2つの文の意味がどの程度等しいかを表す0〜5の実数値を付与した「JSTS」と，2つの文に対して含意，矛盾，中立の三値のラベルを付与した「JNLI」を含みます．質問応答タスクについては，機械読解タスクのデータセット「JSQuAD」と，常識推論能力を評価するための5択問題のデータセット「JCommonsenseQA」を含みます．既存の英語のデータセットを日本語に翻訳するのではなく，クラウドソーシングを用いて一から構築されています．JGLUEv1は2022年3月に公開される予定です．日本語の言語理解のための標準的なベンチマークとして利用され，研究分野全体の発展に貢献することが期待されます．</td></tr>
        </table>

        <h2 id="sponsor">スポンサー賞（全386件中5件）</h2>
        <h3>LegalForce賞</h3>
        <table>
          <tr><td class="pid"><span id="A4-2">A4-2</span></td><td><span class="title">否定の理解へのprompt-based finetuningの効果</span></td><tr><td></td><td>田代真生, 上垣外英剛, 船越孝太郎, 奥村学 (東工大)</td><tr><td></td><td class="award_reason">本論文は，事前学習済み言語モデルを後段タスクに適用するいくつかの手法において，否定表現がどれだけ理解できているかを定量化して比較した論文です．否定表現は文書分類の分類結果など後段タスクの予測結果に大きく影響を与える要素の一つであり，実用上大事な観点であると考えています．論文中では，後段タスクにおける否定認識の影響を適切に分析できるようにAverage Data Point Advantageの指標を用いて様々な観点で比較を行っており，特にprompt-based finetuningによる手法が否定表現をより認識できていることを示しています．この実験結果は実用時に事前学習済み言語モデルを選択する際の有益な手がかりになるという点を評価し，スポンサー賞とさせていただきました．</td></tr>
        </table>
        <h3>NEC賞</h3>
        <table>
          <tr><td class="pid"><span id="A4-5">A4-5</span></td><td><span class="title">四則演算を用いた Transformer の再帰的構造把握能力の調査</span></td><tr><td></td><td>松本悠太 (東北大), 吉川将司 (東北大/理研), Benjamin Heinzerling (理研), 乾健太郎 (東北大/理研)</td><tr><td></td><td class="award_reason">本研究は多くの自然言語処理で用いられるTransformerの再帰的構造をとらえる能力について，同じく再帰的構造を持つ形式的な四則演算を通して検証し，計算の途中結果が中間層において分散的にエンコードされていることを明らかにしています．単独の研究として優れているだけでなく，その結論はTransformerを用いた言語処理の応用を考える多くの人たちにも価値ある洞察を与えるであろう点を評価し，スポンサー賞に選考しました．</td></tr>
        </table>
        <h3>サイバーエージェント賞</h3>
        <table>
          <tr><td class="pid"><span id="B3-2">B3-2</span></td><td><span class="title">後処理ネットワークを用いた強化学習によるタスク指向型対話システムの最適化</span></td><tr><td></td><td>大橋厚元, 東中竜一郎 (名大)</td><tr><td></td><td class="award_reason">一番の理由は，実務に近い課題設定なところです．弊社でもタスク指向型対話のシステムを運用しているんですが，パイプラインベースな手法だと部分最適になってしまう一方で，end-to-end な手法だと細かい制御ができないので，産業応用はまだ難しそうです．その点，この研究では強化学習で後処理することで，パイプラインベースな手法において全体最適を可能とし，タスク成功率を向上させました．例年通り，良い研究が多くて非常に迷いましたが，実働システムへの導入のしやすさだったり，高い汎用性からこの研究を選ばせていただきました．</td></tr>
        </table>
        <h3>富士通賞</h3>
        <table>
          <tr><td class="pid"><span id="C4-3">C4-3</span></td><td><span class="title">Transformerモデルのニューロンには局所的に概念についての知識がエンコードされている</span></td><tr><td></td><td>有山知希 (東北大), Benjamin Heinzerling (理研/東北大), 乾健太郎 (東北大/理研)</td><tr><td></td><td class="award_reason">本論文は，言語モデルが穴埋め問題を解く際に，正答と対応関係のあるニューロン（Feed-Forward層の特定の重み）を探し，そのニューロンの活性度を変更することで正解率が大きく変化することを確かめています．特に品詞により局所性に違いがある可能性を示し，Transformerを用いたモデルの挙動の一端をあきらかにしています．弊社では推論の説明性，説明可能なAIの研究に取り組んでおり，関連する研究と考えスポンサー賞としました．</td></tr>
        </table>
        <h3>Japan Digital Design賞</h3>
        <table>
          <tr><td class="pid"><span id="PH4-11">PH4-11</span></td><td><span class="title">要約の生成過程を考慮した弱教師あり学習による生成型要約のエラー検出</span></td><tr><td></td><td>高塚雅人, 小林哲則, 林良彦 (早大)</td><tr><td></td><td class="award_reason">理由は３点あります．１つ目は，弊社の課題意識に近く，そこにチャレンジした研究だったことです．弊社でも文書自動生成に取り組んでおり，生成文の良し悪しの評価を重要と捉え，「記載内容が事実に基づいているか？根拠として記載すべき事象が網羅されているか？」など試行錯誤しております．受賞論文は，生成モデル側で同様の課題意識を持ち，チャレンジした研究だと評価しました．２つ目は，課題に対し，新規性のある手法で解決策を提示したことです．また，課題意識の説明から納得のいく手法と感じました．３つ目は，実験結果を見ても，既存研究に比べ精度向上が認められたことです．</td></tr>
        </table>

        <h2 id="committee">委員特別賞（対象365件中16件）</h2>
        <table>
          <tr><td class="pid"><span id="B1-4">B1-4</span></td><td><span class="title">対話での共通基盤構築過程における名付けの分析</span></td><tr><td></td><td>齋藤結 (電通大), 光田航, 東中竜一郎 (NTT), 南泰浩 (電通大)</td><tr><td></td><td class="award_reason">【新規性】【将来性】の観点での評価</td></tr>
          <tr><td class="pid"><span id="E1-1">E1-1</span></td><td><span class="title">拡張固有表現に分類された31言語のWikipedia知識ベース</span></td><tr><td></td><td>関根聡, 中山功太, 野本昌子 (理研), 安藤まや (フリー), 隅田飛鳥, 松田耕史 (理研)</td><tr><td></td><td class="award_reason">【将来性】の観点での評価</td></tr>
          <tr><td class="pid"><span id="D2-5">D2-5</span></td><td><span class="title">Vaporetto: 点予測法に基づく高速な日本語トークナイザ</span></td><tr><td></td><td>赤部晃一, 神田峻介 (LegalForce), 小田悠介 (LegalForce/東北大), 森信介 (京大)</td><tr><td></td><td class="award_reason">【有用性】の観点での評価</td></tr>
          <tr><td class="pid"><span id="F2-3">F2-3</span></td><td><span class="title">MioGattoによる数式グラウンディングデータセットの構築</span></td><tr><td></td><td>朝倉卓人, 宮尾祐介 (東大), 相澤彰子 (NII)</td><tr><td></td><td class="award_reason">【新規性】【将来性】の観点での評価</td></tr>
          <tr><td class="pid"><span id="B3-2">B3-2</span></td><td><span class="title">後処理ネットワークを用いた強化学習によるタスク指向型対話システムの最適化</span></td><tr><td></td><td>大橋厚元, 東中竜一郎 (名大)</td><tr><td></td><td class="award_reason">【有用性】【将来性】の観点での評価</td></tr>
          <tr><td class="pid"><span id="A4-1">A4-1</span></td><td><span class="title">確信度を考慮した言語モデルの関係知識評価</span></td><tr><td></td><td>吉川和 (東工大/富士通), 岡崎直観 (東工大)</td><tr><td></td><td class="award_reason">【有用性】の観点での評価</td></tr>
          <tr><td class="pid"><span id="PT2-4">PT2-4</span></td><td><span class="title">どれほどの統語的教示が必要十分なのか？</span></td><tr><td></td><td>能地宏 (LeapMind), 大関洋平 (東大)</td><tr><td></td><td class="award_reason">【有用性】の観点での評価</td></tr>
          <tr><td class="pid"><span id="A5-5">A5-5</span></td><td><span class="title">Transformerにおけるフィードフォワードネットの作用</span></td><tr><td></td><td>小林悟郎 (東北大), 栗林樹生 (東北大/Langsmith), 横井祥, 乾健太郎 (東北大/理研)</td><tr><td></td><td class="award_reason">【新規性】【有用性】の観点での評価</td></tr>
          <tr><td class="pid"><span id="E5-5">E5-5</span></td><td><span class="title">複数映像の抽象化を要するキャプション生成</span></td><tr><td></td><td>高橋力斗, Chenhui Chu, 黒橋禎夫 (京大)</td><tr><td></td><td class="award_reason">【新規性】 の観点での評価</td></tr>
          <tr><td class="pid"><span id="C6-3">C6-3</span></td><td><span class="title">近傍の事例を用いた非自己回帰生成</span></td><tr><td></td><td>丹羽彩奈, 高瀬翔, 岡崎直観 (東工大)</td><tr><td></td><td class="award_reason">【有用性】の観点での評価</td></tr>
          <tr><td class="pid"><span id="E6-4">E6-4</span></td><td><span class="title">動画タイトルを用いたサムネイル画像の自動選択手法の提案</span></td><tr><td></td><td>嘉田紗世, 山野陽祐, 新美茜, 田森秀明, 小海則人 (朝日新聞社), 岡崎直観 (東工大), 乾健太郎 (東北大/理研)</td><tr><td></td><td class="award_reason">【新規性】【有用性】の観点での評価</td></tr>
          <tr><td class="pid"><span id="PT3-16">PT3-16</span></td><td><span class="title">単語埋め込みを利用した商品に対するキーワードの予測</span></td><tr><td></td><td>山口泰弘, 深澤祐援, 原島純 (クックパッド)</td><tr><td></td><td class="award_reason">【有用性】の観点での評価</td></tr>
          <tr><td class="pid"><span id="PH4-7">PH4-7</span></td><td><span class="title">LSTMの無変化性バイアスの実験的分析</span></td><tr><td></td><td>石井太河, 上田亮, 宮尾祐介 (東大)</td><tr><td></td><td class="award_reason">【有用性】の観点での評価</td></tr>
          <tr><td class="pid"><span id="PH4-12">PH4-12</span></td><td><span class="title">曖昧性を含む翻訳に着目したマルチモーダル機械翻訳データセットの構築方法の検討</span></td><tr><td></td><td>Yihang Li, 清水周一郎, Chenhui Chu, 黒橋禎夫 (京大)</td><tr><td></td><td class="award_reason">【将来性】の観点での評価</td></tr>
          <tr><td class="pid"><span id="PT4-11">PT4-11</span></td><td><span class="title">JParaCrawl v3.0: 大規模日英対訳コーパス</span></td><tr><td></td><td>森下睦, 帖佐克己 (NTT), 鈴木潤 (東北大), 永田昌明 (NTT)</td><tr><td></td><td class="award_reason">【有用性】の観点での評価</td></tr>
          <tr><td class="pid"><span id="D7-3">D7-3</span></td><td><span class="title">分散表現を用いたロマンス語同源語動詞の意味変化の分析</span></td><tr><td></td><td>川崎義史, Maëlys Salingre (東大), Marzena Karpinska (University of Massachusetts Amherst), 高村大也 (産総研), 永田亮 (甲南大)</td><tr><td></td><td class="award_reason">【新規性】の観点での評価</td></tr>
        </table>

        <p align="center"><a href="#menu">top へ戻る</a></p>

        <footer>
          最終更新日: 2022年 4月 1日<br />
          言語処理学会第28回年次大会 プログラム委員会・大会委員会<br />
          <address>nlp2022-inquiry (at) ml.anlp.jp</address>
        </footer>

      </div> <!-- end of span9 -->
    </div> <!-- end of row -->
  </div> <!-- end of container -->
</body>

</html>
