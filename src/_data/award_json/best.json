{
	"name": "最優秀賞",
	"tag": "best",
	"counts": "（全386件中2件）",
	"awarded":
		[
			{
				"id": "G1-4",
				"title": "強化学習における画像キャプションの低識別性問題とLong-Tail分類手法を用いた対処",
				"awardees": "本多右京, 渡辺太郎 (NAIST), 松本裕治 (理研)",
				"award_reason": "画像キャプション生成において強化学習は有効な手法ですが，一般的な内容のキャプションを生成しやすいという低識別性の問題があります．本論文では，この問題に対処するため，画像分類で用いられているlong-tail分類手法を応用することによって，キャプション中の語彙を増加させる手法を提案しています．実験によって，提案手法が既存モデルと比べて，語彙を増加させるとともに，識別性を顕著に向上させることを確認しています．また，提案手法は学習済みの既存モデルをfine-tuningするものであり，計算コストが低く，実用性も高いと考えられます．これらの貢献から最優秀賞にふさわしいと判断しました．"
			},
			{
				"id": "A3-1",
				"title": "ニューラル言語モデルの効率的な学習に向けた代表データ集合の獲得",
				"awardees": "鈴木潤 (グーグル/東北大), 全炳河, 賀沢秀人 (グーグル)",
				"award_reason": "ニューラル言語モデルは近年の自然言語処理タスクの根幹を担う基盤技術ですが，モデル構築には潤沢な計算リソースが必要になります．本論文では，ニューラル言語モデルを構築する際に，学習データを全て用いるのではなく，選択した代表的なデータ集合のみを用いて学習した場合に，性能を維持できるか否かを検証しています．実験によって，提案手法を用いることで，21分の1程度までに学習データを削減したとしても，全ての学習データを用いて学習した場合と比較して性能が維持できるということが示されました．本手法を用いることで，ニューラル言語モデルの構築を様々な研究者ができるようになると考えられ，有用性，発展性の高い研究であると言えます．これらの貢献から最優秀賞にふさわしいと判断しました．"
			}
		]
}